# noiseseeker
==============

noiseseeker is an algorithm which aims at exploring potential order in noise. More likely than not this project
is utterly useless, but the underlying questions raised are nevertheless interesting:

- What are the properties of humanly recognizable 'noise'?
- What are the properties of humanly recognizable patterns?
- What makes an image more recognizable as 'anti-noise', than others?

Given our field of vision there exists an upper boundary for how many 'pixels' we can perceive. If, for the sake of simplicity,
we assume that all humans perceive the same amount of 'pixels' and 'ray colors', there must exist a finite number of how many
images we can sense with our eyes. Let's assume this number is denoted by X. What percentage of X is recognizable as something of
our own world? E.g. lines, circles, or even pictures of humans or houses? Furthermore, can we develop an algorithm to a) detect
images that are recognizable by humans as something not made by a computer, and b) does it exist a pattern of distribution between pictures
that are humanly recognizable? Although no parallels can be drawn, a similar question exists for the distribution of prime numbers.

Early Results
--------------


